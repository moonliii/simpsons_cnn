{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# imports\nimport numpy as np\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Dropout, BatchNormalization, Flatten, SimpleRNN, Input, Activation,Add\nfrom keras.layers import Conv2D, MaxPooling2D, AveragePooling2D ,ZeroPadding2D\nfrom keras.utils.np_utils import to_categorical\nfrom keras.optimizers import adam_v2, rmsprop_v2\nimport glob\nimport sklearn\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport matplotlib.pyplot as plt\nimport os","metadata":{"_kg_hide-input":false,"execution":{"iopub.status.busy":"2021-12-19T16:15:07.927926Z","iopub.execute_input":"2021-12-19T16:15:07.928409Z","iopub.status.idle":"2021-12-19T16:15:07.94172Z","shell.execute_reply.started":"2021-12-19T16:15:07.928356Z","shell.execute_reply":"2021-12-19T16:15:07.940961Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# global config\nmap_characters = {0: 'abraham_grampa_simpson', 1: 'apu_nahasapeemapetilon', 2: 'moe_szyslak', \n        3: 'charles_montgomery_burns', 4: 'chief_wiggum', 5: 'comic_book_guy', 6: 'edna_krabappel', \n        7: 'homer_simpson', 8: 'kent_brockman', 9: 'krusty_the_clown', 10: 'lenny_leonard', 11:'lisa_simpson',\n        12: 'marge_simpson', 13: 'mayor_quimby',14:'milhouse_van_houten', 15: 'bart_simpson', \n        16: 'ned_flanders', 17: 'nelson_muntz', 18: 'principal_skinner', 19: 'sideshow_bob'}\n\nimg_size = 64\nbatch_size = 32\nepochs = 100\nnum_classes = len(map_characters)\nvalid_rate = 0.2\ninitial_lr = 0.001","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:15:17.07326Z","iopub.execute_input":"2021-12-19T16:15:17.073521Z","iopub.status.idle":"2021-12-19T16:15:17.080135Z","shell.execute_reply.started":"2021-12-19T16:15:17.07349Z","shell.execute_reply":"2021-12-19T16:15:17.079188Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# load the test set and preprocess\ndef load_test_set(dir_name):\n    X_test, y_test = [], []\n    for image_name in os.listdir(dir_name):\n        character_name = '_'.join(image_name.split('_')[:-1])\n        label = [label for label, character in map_characters.items() if character == character_name][0]\n        image = cv2.imread(dir_name+'/'+image_name)\n        image = cv2.resize(image, (img_size, img_size)).astype('float32')/255.\n        X_test.append(image)\n        y_test.append(label)\n    return np.array(X_test), np.array(y_test)\n\ndef load_train_set(dir_name):\n    X_train, y_train = [], []\n    for label, character in map_characters.items():\n        list_images = os.listdir(dir_name+'/'+character)\n        for image_name in list_images[0:150]:\n            image = cv2.imread(dir_name+'/'+character+'/'+image_name)\n            image = cv2.resize(image, (img_size, img_size)).astype('float32')/255.\n            X_train.append(image)\n            y_train.append(label)   \n    return np.array(X_train), np.array(y_train)\n\nX_test, y_test = load_test_set(\"/kaggle/input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset\")\nX_train, y_train = load_train_set(\"/kaggle/input/the-simpsons-characters-dataset/simpsons_dataset/simpsons_dataset\")\n# transfer labels to one-hot vectors\ny_train = to_categorical(y_train, num_classes=num_classes)\ny_test = to_categorical(y_test, num_classes=num_classes)\n# split training data to training data and validation data\n# valid_num = int(X_train.shape[0] * valid_rate)\n# X_train, X_valid = X_train[:-valid_num], X_train[-valid_num:]\n# y_train, y_valid = y_train[:-valid_num], y_train[-valid_num:]\n(X_train, X_valid, y_train, y_valid) = train_test_split(X_train, y_train, test_size=valid_rate, stratify=y_train)\n\nprint(f'X_train shape:{X_train.shape} y_train shape:{y_train.shape}')\nprint(f'X_valid shape:{X_valid.shape} y_valid shape:{y_valid.shape}')\nprint(f'X_test shape:{X_test.shape} y_test shape:{y_test.shape}')","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:15:19.995744Z","iopub.execute_input":"2021-12-19T16:15:19.996312Z","iopub.status.idle":"2021-12-19T16:15:27.979329Z","shell.execute_reply.started":"2021-12-19T16:15:19.996272Z","shell.execute_reply":"2021-12-19T16:15:27.977817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create cnn model\n# VGG-like\ndef create_VGGLike_model(input_shape=(img_size,img_size,3)):\n    model = Sequential()\n\n    model.add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu',input_shape=input_shape))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=64,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(filters=128,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=128,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(filters=256,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=256,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=256,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters=512,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=512,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=512,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n    \n    model.add(Conv2D(filters=512,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=512,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters=512,kernel_size=(3,3),padding='Same',activation='relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.25))\n\n    model.add(Flatten())\n    model.add(Dense(4096, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes, activation='softmax'))\n#     optimizer = rmsprop_v2.RMSprop(learning_rate=0.0001, decay=1e-6)\n    optimizer = adam_v2.Adam(learning_rate=initial_lr, decay=initial_lr / epochs)\n    model.compile(loss='categorical_crossentropy',\n        optimizer=optimizer,\n        metrics=['accuracy'])\n#     keras.utils.vis_utils.plot_model(model, to_file='cnn_architecture.png', show_shapes=True, show_layer_names=True)\n    print(model.summary())\n    return model\n\nmodel = create_VGGLike_model()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def identity_block(X, filters):\n    f1, f2, f3 = filters\n    X_residual = X\n    \n    X = Conv2D(filters=f1, kernel_size=(1,1))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(filters=f2, kernel_size=(3,3), padding='same')(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(filters=f3, kernel_size=(1,1))(X)\n    X = BatchNormalization(axis=3)(X)\n    \n    X = Add()([X, X_residual])\n    X = Activation('relu')(X)\n    \n    return X\n    \ndef convolution_block(X, filters):\n    f1, f2, f3 = filters\n    X_residual = X\n    \n    X = Conv2D(filters=f1, kernel_size=(1,1))(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(filters=f2, kernel_size=(3,3), padding='same')(X)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    \n    X = Conv2D(filters=f3, kernel_size=(1,1))(X)\n    X = BatchNormalization(axis=3)(X)\n    \n    X_residual = Conv2D(f3, kernel_size=(1,1))(X_residual)\n    X_residual = BatchNormalization(axis=3)(X_residual)\n    \n    X = Add()([X, X_residual])\n    X = Activation('relu')(X)\n    \n    return X\n\ndef create_ResNetLike_model(input_shape=(img_size,img_size,3)):\n    X_input = Input(input_shape)\n    # X = ZeroPadding2D((3,3))(X_input)\n    X = Conv2D(64, (7,7), strides=(2,2), padding='same')(X_input)\n    X = BatchNormalization(axis=3)(X)\n    X = Activation('relu')(X)\n    X = MaxPooling2D((3,3), strides=(2,2))(X)\n    \n    X = convolution_block(X, filters=[64,64,256])\n    X = identity_block(X, filters=[64,64,256])\n    X = identity_block(X, filters=[64,64,256])\n    \n    X = convolution_block(X, filters=[128,128,512])\n    X = identity_block(X, filters=[128,128,512])\n    X = identity_block(X, filters=[128,128,512])\n    X = identity_block(X, filters=[128,128,512])\n    \n    X = convolution_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    X = identity_block(X, filters=[256,256,1024])\n    \n    X = convolution_block(X, filters=[512,512,2048])\n    X = identity_block(X, filters=[512,512,2048])\n    X = identity_block(X, filters=[512,512,2048])\n    X = AveragePooling2D((2,2))(X)\n    \n    X = Flatten()(X)\n    X = Dense(num_classes, activation='softmax')(X)\n    \n    model = Model(inputs=X_input, outputs=X)\n    model.compile(loss='categorical_crossentropy',\n        optimizer='adam',\n        metrics=['accuracy'])\n    print(model.summary())\n    \n    return model\n    \nmodel = create_ResNetLike_model()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:15:35.76947Z","iopub.execute_input":"2021-12-19T16:15:35.769724Z","iopub.status.idle":"2021-12-19T16:15:36.70022Z","shell.execute_reply.started":"2021-12-19T16:15:35.769693Z","shell.execute_reply":"2021-12-19T16:15:36.699462Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# data augumentation and fit model\ndef fit_model(model, X_train, y_train, X_valid, y_valid):\n    data_generator = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        width_shift_range=0.1,\n        height_shift_range=0.1,\n        horizontal_flip=True,\n        vertical_flip=False)\n    data_generator.fit(X_train)\n\n    history = model.fit_generator(data_generator.flow(X_train, y_train, batch_size=batch_size),\n                                  steps_per_epoch=X_train.shape[0]//batch_size,\n                                  validation_data=(X_valid, y_valid),\n                                  epochs=epochs)\n    \n    return model, history\n\nmodel, history = fit_model(model, X_train, y_train, X_valid, y_valid)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:15:44.946644Z","iopub.execute_input":"2021-12-19T16:15:44.947333Z","iopub.status.idle":"2021-12-19T16:38:37.142729Z","shell.execute_reply.started":"2021-12-19T16:15:44.947291Z","shell.execute_reply":"2021-12-19T16:38:37.142007Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# create rnn model\ntime_steps = img_size\ninput_size = img_size * 3  # reserve rgb\nhidden_layer = 256 \n\nX_train = X_train.reshape(-1, time_steps, input_size)\nX_test = X_test.reshape(-1, time_steps, input_size)\nX_valid = X_valid.reshape(-1, time_steps, input_size)\nprint(X_train.shape, X_valid.shape)\n\ndef create_rnn_model():\n    model = Sequential()\n    # RNN cell\n    model.add(SimpleRNN(hidden_layer))\n    model.add(Dense(num_classes, activation='softmax'))\n    \n    optimizer = rmsprop_v2.RMSprop(learning_rate=0.0001, decay=1e-6)\n    model.compile(loss='categorical_crossentropy',\n        optimizer=optimizer,\n        metrics=['accuracy'])\n    \n    model.build((None, time_steps, input_size))\n    print(model.summary())\n    return model\n\nmodel = create_rnn_model()\nhistory = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), batch_size=batch_size, epochs=epochs)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:40:16.834061Z","iopub.execute_input":"2021-12-19T16:40:16.834803Z","iopub.status.idle":"2021-12-19T16:40:25.129162Z","shell.execute_reply.started":"2021-12-19T16:40:16.834748Z","shell.execute_reply":"2021-12-19T16:40:25.128169Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def plot_training_history(history):\n    print(history.history)\n    # plot accuracy history\n    plt.plot(history.history['accuracy'], label='accuracy')\n    plt.plot(history.history['val_accuracy'], label='val_accuracy')\n    plt.title('Model accuracy')\n    plt.ylabel('Accuarcy')\n    plt.xlabel('Epoch')\n    plt.legend(loc='upper left')\n    plt.show()\n\n    # plot loss history\n    plt.plot(history.history['loss'], label='loss')\n    plt.plot(history.history['val_loss'], label='val_loss')\n    plt.title('Model loss')\n    plt.ylabel('Loss')\n    plt.xlabel('Epoch')\n    plt.legend(loc='upper left')\n    plt.show()\n    \nplot_training_history(history)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:40:28.778306Z","iopub.execute_input":"2021-12-19T16:40:28.778843Z","iopub.status.idle":"2021-12-19T16:40:29.181286Z","shell.execute_reply.started":"2021-12-19T16:40:28.7788Z","shell.execute_reply":"2021-12-19T16:40:29.180601Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# evaluate model and plot results\ndef evaluate_model(model, X_test, y_test):\n    test_loss, test_acc = model.evaluate(X_test, y_test, verbose=0)\n    print(f'test loss: {test_loss} test accuracy: {test_acc}')\n    y_pred = model.predict(X_test)\n    y_pred_classes = np.argmax(y_pred, axis=1)\n    y_true_classes = np.argmax(y_test, axis=1)\n    print(metrics.classification_report(y_true_classes, y_pred_classes, target_names=list(map_characters.values())), sep='')\n\n    plt.figure(figsize=(8,8))\n    cfs_matrix = metrics.confusion_matrix(y_true_classes, y_pred_classes)\n    plt.imshow(cfs_matrix, interpolation='nearest')\n    plt.colorbar()\n    character_names = list(map_characters.values())\n    tick_labels = np.arange(len(character_names))\n    plt.xticks(tick_labels, character_names, rotation=90)\n    plt.yticks(tick_labels, character_names)\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \nevaluate_model(model, X_test, y_test)","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:40:47.162945Z","iopub.execute_input":"2021-12-19T16:40:47.163514Z","iopub.status.idle":"2021-12-19T16:40:48.625232Z","shell.execute_reply.started":"2021-12-19T16:40:47.163475Z","shell.execute_reply":"2021-12-19T16:40:48.62455Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def random_predict():\n    image_set = [k for k in glob.glob('/kaggle/input/the-simpsons-characters-dataset/kaggle_simpson_testset/kaggle_simpson_testset/*.*')]\n    plt.figure(figsize=(10,10))\n    plt.subplots_adjust(wspace=0, hspace=0)\n\n    for i in range(9):\n        img_file = np.random.choice(image_set)\n        character_name = [name for name in map_characters.values() if name in img_file][0].split('_')[0].title()\n        image = cv2.imread(img_file)\n        show_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (img_size, img_size)).astype('float32')/255.\n        y_pred = model.predict(image.reshape(1,img_size,img_size,3))[0]\n        text = sorted(['{:s} : {:.2f}%'.format(map_characters[k].split('_')[0].title(), 100*v) for k,v in enumerate(y_pred)], \n           key=lambda x:float(x.split(':')[1].split('%')[0]), reverse=True)[:3]\n\n        # resize before showing\n        show_image = cv2.resize(show_image, (352,352))\n        cv2.rectangle(show_image, (0,260), (215,352),(255,255,255),-1)\n        font = cv2.FONT_HERSHEY_SIMPLEX\n        cv2.putText(show_image, 'Name: %s'%character_name, (10,280), font, 0.7, (0,0,0), 2, cv2.LINE_AA)\n        for k, v in enumerate(text):\n            cv2.putText(show_image, v, (10, 300+k*18), font, 0.65, (0,0,0), 2, cv2.LINE_AA)\n        plt.subplot(3,3,i+1)\n        plt.imshow(show_image);plt.axis('off')\n\nrandom_predict()","metadata":{"execution":{"iopub.status.busy":"2021-12-19T16:40:58.474275Z","iopub.execute_input":"2021-12-19T16:40:58.474826Z","iopub.status.idle":"2021-12-19T16:40:58.584308Z","shell.execute_reply.started":"2021-12-19T16:40:58.474768Z","shell.execute_reply":"2021-12-19T16:40:58.582978Z"},"trusted":true},"execution_count":null,"outputs":[]}]}
